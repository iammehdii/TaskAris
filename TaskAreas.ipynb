{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TaskAreas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iammehdii/TaskAris/blob/NewBranchAris/TaskAreas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVMVWrLudr2b"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import cv2\n",
        "from imutils import paths\n",
        "from tensorflow.keras import backend as K\n",
        "import os\n",
        "import random\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMx7QY__hfBj"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Q2tfeVirRT",
        "outputId": "55ed0624-8446-4bbb-c00e-db6894845101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# !mkdir('/content/drive/My Drive/2020-11-01-Data') ## Uncomment this line if there is not such directory\n",
        "drive.mount('/content/drive')\n",
        "# !unzip '/content/drive/My Drive/2020-11-01-Data.zip' -d '/content/drive/My Drive/2020-11-01-Data'  ## Uncomment this line if u want to unzip \n",
        "input_image_directory = '/content/drive/My Drive/2020-11-01-Data/2020-11-01'\n",
        "imagePaths = sorted(list(paths.list_images(input_image_directory)))\n",
        "np.random.seed(0)\n",
        "imagePaths = np.random.permutation(imagePaths)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yJpOvwBfKwj"
      },
      "source": [
        "IMAGE_DIMS = (224, 224, 3)   # # if u want to use VGG  or ReSnet50 uncomment this line\n",
        "# IMAGE_DIMS = (299, 299, 3) # if u want to use InceptionV3 uncomment this line\n",
        "# initialize the data and labels\n",
        "data = []\n",
        "labels = []\n",
        "size = []\n",
        "for imagePath in imagePaths:\n",
        "  image = cv2.imread(imagePath)\n",
        "  a=image.shape[:2]\n",
        "  size.append(list(a))\n",
        "  image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "  image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  data.append(image)\n",
        "  label = imagePath.split(os.path.sep)[-2]\n",
        "  labels.append(label)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T5so1-elcLb"
      },
      "source": [
        "## preprocess images and split data to train and test\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.1, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2V6hHWTsz21"
      },
      "source": [
        "## this function takes source model like ResNet50 and makes new model. \n",
        "#INPUTS \n",
        "# model: source model like ResNet or VGG\n",
        "# opt: optimizer object for compiling model\n",
        "#nClass: number of classes\n",
        "# OUTPUT\n",
        "# model: created model\n",
        "def makeCustomeModel(model,nClass):\n",
        "  predictions0 = keras.layers.Dense(128, activation='softmax')(model.layers[-2].output)\n",
        "  predictions2 = keras.layers.Dense(nClass, activation='softmax')(predictions0)\n",
        "  model = tf.keras.Model(inputs=model.input, outputs=predictions2)\n",
        "  return model\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z524NMJ3EfD"
      },
      "source": [
        "## choose source model by setting NUMBER\n",
        "# be carefule about IMAGE_DIMS(u set it before)\n",
        "NUMBER = 1 \n",
        "###################ResNet50\n",
        "if NUMBER == 1:\n",
        "  sourceModel = tf.keras.applications.ResNet50(\n",
        "      include_top=True,\n",
        "      weights=\"imagenet\",\n",
        "      # weights=None,\n",
        "      input_shape=(IMAGE_DIMS[0],IMAGE_DIMS[1],3),\n",
        "      pooling=True  )\n",
        "########## InceptionV3\n",
        "elif  NUMBER == 2:\n",
        "  sourceModel = tf.keras.applications.InceptionV3(\n",
        "      include_top=True,\n",
        "      weights=\"imagenet\",\n",
        "      input_tensor=None,\n",
        "      input_shape=(IMAGE_DIMS[0],IMAGE_DIMS[1],3),\n",
        "      pooling=None,\n",
        "      classes=6,\n",
        "      classifier_activation=\"softmax\"\n",
        "  )\n",
        "elif  NUMBER == 3:\n",
        "###############VGG16\n",
        "  sourceModel = keras.applications.vgg16.VGG16(include_top=True, input_shape = (IMAGE_DIMS[0],IMAGE_DIMS[1],3), weights=\"imagenet\")\n",
        "###freeze all layers in source model except BatchNormalization layer. also change momentum of these layers \n",
        "# decreasing  momentum helps us to have good preiction even few epochs\n",
        "for layer in sourceModel.layers:\n",
        "    if isinstance(layer, keras.layers.BatchNormalization):\n",
        "        layer.trainable = True\n",
        "        layer.momentum = 0.01\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "sourceModel.summary()        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to9wyzBe3Yql"
      },
      "source": [
        "INIT_LR = 0.01\n",
        "EPOCHS = 50\n",
        "BS = 20\n",
        "numClass = 6\n",
        "opt = keras.optimizers.Adam(lr=INIT_LR)\n",
        "finalModel = makeCustomeModel(sourceModel, numClass)\n",
        "#### unfreeze last layers to have good convergence. \n",
        "for layer in finalModel.layers[170:]: ## change depth if u dont use Resnet. set trainable for layers end-10 :end\n",
        "  layer.trainable = True\n",
        "# finalModel.summary()\n",
        "finalModel.compile(optimizer=opt, loss='categorical_crossentropy', \tmetrics=tf.keras.metrics.categorical_accuracy)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hKxYuBVtGrC"
      },
      "source": [
        "## this functions takes 3 inputs and make a callbacks_list which used for storing best models in specific address and specific name\n",
        "def pathToSaveCheckpoint(pathPreFix,folderNam, CheckPointName):\n",
        "  path = pathPreFix + '/' + folderNam \n",
        "  filePath = path + '/' + CheckPointName\n",
        "  os.mkdir( path )\n",
        "  checkpoint = keras.callbacks.ModelCheckpoint(filePath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "  callbacks_list = [checkpoint]\n",
        "  return filePath, callbacks_list"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irJzy1I4WW4P"
      },
      "source": [
        "##### this function takes features and labels,... and learns the model. It 's Possible to choose learning with or without data augmentaion\n",
        "# INPUTS:\n",
        "# trainX: features \n",
        "# trainY : labels\n",
        "# compiledModel: model, it should be compiled before passing to function\n",
        "# batchSize: size of batch\n",
        "# useAug: determine how to model learns (with or without data augmentation)\n",
        "#callbacks_list: for storing only best trained model based on choosed parameter(val_accuracy or val loss)\n",
        "def doTrain(trainX, trainY, compiledModel,callbacks_list,batchSize, useAug=False):\n",
        "  model =compiledModel\n",
        "   \n",
        "  if useAug :\n",
        "    (trainX, validationX, trainY, validationY) = train_test_split(trainX, trainY, test_size=0.1,\n",
        "  random_state=40 )\n",
        "    aug = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=10, width_shift_range=0.1,\n",
        "      height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
        "      horizontal_flip=True, fill_mode=\"nearest\")\n",
        "    it =aug.flow(x= trainX, y= trainY,batch_size=batchSize)\n",
        "    itValidation =aug.flow(x= validationX, y= validationY,batch_size=batchSize)\n",
        "\n",
        "    H = model.fit_generator(it,epochs=EPOCHS,validation_data=itValidation,callbacks=callbacks_list)\n",
        "  \n",
        "  else:\n",
        "    H = model.fit(x=trainX, y=trainY, batch_size=batchSize,\n",
        "      validation_split= 0.1 ,\n",
        "      steps_per_epoch=None,\n",
        "      epochs=EPOCHS, verbose=1,callbacks=callbacks_list)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo8wPa1gBE4D"
      },
      "source": [
        "def doTest(model, testX, testY, batchSize):\n",
        "  predY = model.predict(x= testX,batch_size=batchSize)\n",
        "  cateCrossEntropy = tf.keras.losses.CategoricalCrossentropy()\n",
        "  testLoss  = cateCrossEntropy(testY, predY).np()\n",
        "  print('loss for test images\\n', testLoss )\n",
        "  print('confusion_matrix\\n')\n",
        "  print(metrics.confusion_matrix(testY.argmax(axis=1), predY.argmax(axis=1)),'\\n')\n",
        "  print('report\\n')\n",
        "  print(metrics.classification_report(testY.argmax(axis=1), predY.argmax(axis=1)))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3HhDvemi86F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je_V44fdBIbi",
        "outputId": "916d30af-bf48-4875-cfee-b92110f5cd1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "### load the best model and Test it\n",
        "pathToBestModel='/content/drive/My Drive/checkPointResNet/weights-improvement.hdf5'\n",
        "loadedModel = tf.keras.models.load_model(pathToBestModel)\n",
        "doTest(loadedModel, testX, testY, BS)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion_matrix\n",
            "\n",
            "[[3 0 0 0 0 0]\n",
            " [0 4 0 0 0 1]\n",
            " [0 0 3 1 0 0]\n",
            " [0 0 0 4 0 0]\n",
            " [0 0 0 0 0 7]\n",
            " [0 0 0 0 0 7]] \n",
            "\n",
            "report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      0.80      0.89         5\n",
            "           2       1.00      0.75      0.86         4\n",
            "           3       0.80      1.00      0.89         4\n",
            "           4       0.00      0.00      0.00         7\n",
            "           5       0.47      1.00      0.64         7\n",
            "\n",
            "    accuracy                           0.70        30\n",
            "   macro avg       0.71      0.76      0.71        30\n",
            "weighted avg       0.62      0.70      0.63        30\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZB74CFpNU1b"
      },
      "source": [
        "################## Predict \n",
        "import pandas as pd\n",
        "# !mkdir('/content/drive/My Drive/predictData') ## Uncomment this line if there is not such directory\n",
        "# drive.mount('/content/drive')\n",
        "# !unzip '/content/drive/My Drive/predict.zip' -d '/content/drive/My Drive/predictData'  ## Uncomment this line if u want to unzip \n",
        "\n",
        "pathToImage = '/content/drive/My Drive/predictData'\n",
        "imagePaths = sorted(list(paths.list_images(pathToImage)))\n",
        "# doTest(loadedModel, testX, testY, BS)\n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Hz2edDKpk-"
      },
      "source": [
        "imagePaths\n",
        "imageName = []\n",
        "for image in imagePaths:\n",
        "  name = image.split('/')[-1]\n",
        "  imageName.append(name)\n",
        "imageName\n",
        "classNames = ['bulldog-french', 'chow', 'dingo', 'doberman', 'germanshepherd', 'husky']"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiSmGc5TKrVn"
      },
      "source": [
        "pathToBestModel='/content/drive/My Drive/checkPointResNet/weights-improvement.hdf5'\n",
        "loadedModel = tf.keras.models.load_model(pathToBestModel)\n",
        "# doTest(loadedModel, testX, testY, BS)\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KmF0mFGPI-Q"
      },
      "source": [
        "IMAGE_DIMS = (224, 224, 3)   # # if u want to use VGG  or ReSnet50 uncomment this line\n",
        "# IMAGE_DIMS = (299, 299, 3) # if u want to use InceptionV3 uncomment this line\n",
        "# initialize the data and labels\n",
        "data = []\n",
        "for imagePath in imagePaths:\n",
        "  image = cv2.imread(imagePath)\n",
        "  image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "  image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  data.append(image)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcHRNQSaPjso"
      },
      "source": [
        "data = np.array(data, dtype=\"float\") / 255.0\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puVEfxcAO8ei",
        "outputId": "2bc7c2ee-b21f-4d67-97e9-f635a952e459",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# pathToBestModel = \"/content/drive/My Drive/checkPointResNet/weights-improvement.hdf5\"\n",
        "predY = loadedModel.predict(x= data,batch_size=20)\n",
        "# predY.argmax(axis= 1)\n",
        "# nnnn = classNames[predY]\n",
        "imageName\n",
        "predictedClass = []\n",
        "for i in range(len(imageName)):\n",
        "  mm = classNames[predY[i].argmax(axis= 0)]\n",
        "  predictedClass.append(mm)\n",
        "predictedClass"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bulldog-french',\n",
              " 'husky',\n",
              " 'chow',\n",
              " 'bulldog-french',\n",
              " 'husky',\n",
              " 'husky',\n",
              " 'doberman',\n",
              " 'doberman',\n",
              " 'doberman',\n",
              " 'bulldog-french',\n",
              " 'bulldog-french',\n",
              " 'husky',\n",
              " 'husky',\n",
              " 'chow',\n",
              " 'chow',\n",
              " 'chow',\n",
              " 'chow',\n",
              " 'chow',\n",
              " 'dingo',\n",
              " 'dingo']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVqXm_aPQtRP",
        "outputId": "341b38bd-17bd-48e6-b556-9e5073b58b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "A = ['predicted class']\n",
        "df = pd.DataFrame(predictedClass,index=imageName,columns=A)\n",
        "df"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>IMG_20190826_121528_876.jpg</th>\n",
              "      <td>bulldog-french</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02086240_1142.jpg</th>\n",
              "      <td>husky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02086240_4127.jpg</th>\n",
              "      <td>chow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02086240_762.jpg</th>\n",
              "      <td>bulldog-french</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02106662_3431.jpg</th>\n",
              "      <td>husky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02106662_808.jpg</th>\n",
              "      <td>husky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02107142_1193.jpg</th>\n",
              "      <td>doberman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02107142_1306.jpg</th>\n",
              "      <td>doberman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02107142_3236.jpg</th>\n",
              "      <td>doberman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02108915_3464.jpg</th>\n",
              "      <td>bulldog-french</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02108915_4066.jpg</th>\n",
              "      <td>bulldog-french</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02110185_353.jpg</th>\n",
              "      <td>husky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02110185_699.jpg</th>\n",
              "      <td>husky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02112018_1325.jpg</th>\n",
              "      <td>chow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02112018_904.jpg</th>\n",
              "      <td>chow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02112137_2020.jpg</th>\n",
              "      <td>chow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02112137_2739.jpg</th>\n",
              "      <td>chow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02112137_2845.jpg</th>\n",
              "      <td>chow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02115641_1380.jpg</th>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n02115641_3494.jpg</th>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            predicted class\n",
              "IMG_20190826_121528_876.jpg  bulldog-french\n",
              "n02086240_1142.jpg                    husky\n",
              "n02086240_4127.jpg                     chow\n",
              "n02086240_762.jpg            bulldog-french\n",
              "n02106662_3431.jpg                    husky\n",
              "n02106662_808.jpg                     husky\n",
              "n02107142_1193.jpg                 doberman\n",
              "n02107142_1306.jpg                 doberman\n",
              "n02107142_3236.jpg                 doberman\n",
              "n02108915_3464.jpg           bulldog-french\n",
              "n02108915_4066.jpg           bulldog-french\n",
              "n02110185_353.jpg                     husky\n",
              "n02110185_699.jpg                     husky\n",
              "n02112018_1325.jpg                     chow\n",
              "n02112018_904.jpg                      chow\n",
              "n02112137_2020.jpg                     chow\n",
              "n02112137_2739.jpg                     chow\n",
              "n02112137_2845.jpg                     chow\n",
              "n02115641_1380.jpg                    dingo\n",
              "n02115641_3494.jpg                    dingo"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    }
  ]
}